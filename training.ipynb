{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5OK4Mxr29oN"
      },
      "outputs": [],
      "source": [
        "#in this file we wil be training the Neural Network\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "#firstly we need to get the training sample and the labels\n",
        "df = pd.read_csv('/content/output_sentiment.csv')\n",
        "\n",
        "#dataset will be the training sample with shape (n,3,1) where n is the number of rows in /content/output_sentiment .csv\n",
        "average_sentiment_per_day = df.groupby('date')[[\"close\",\"sentiment\",\"volume\"]].mean().reset_index()\n",
        "dataset=average_sentiment_per_day[[\"close\",\"sentiment\",\"volume\"]].values.tolist()\n",
        "\n",
        "#we create the labels, they will be the next close price value for each element in dataset\n",
        "df = pd.read_csv('a.csv')\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "#get list of dates from the dataset\n",
        "date_list = average_sentiment_per_day[\"date\"].tolist()\n",
        "next_rows_df = pd.DataFrame()\n",
        "\n",
        "#for each element add to the labels the close price of the next day of that element\n",
        "for date in date_list:\n",
        "    # Find the index of the date\n",
        "    matching_indices = df.index[df['date'] == date].tolist()\n",
        "    if matching_indices:\n",
        "        #make sure the last element is not the last row of the a.csv file other wise there will be no label\n",
        "        if matching_indices[0]<len(df)-1:\n",
        "          next_index = matching_indices[0] + 1\n",
        "          if next_index<len(df):\n",
        "              # Append the next row to the next_rows_df DataFrame\n",
        "              next_rows_df = next_rows_df.append(df.iloc[next_index])\n",
        "    else:\n",
        "      #remove the element with no label\n",
        "      dataset.pop()\n",
        "\n",
        "\n",
        "correct_tmp=next_rows_df[\"close\"].tolist()\n",
        "\n",
        "#partition dataset into training sample and validation and test sample\n",
        "training_tmp=dataset[:500]+dataset[600:]\n",
        "correct_tmp1=correct_tmp[:500]+correct_tmp[600:]\n",
        "test_sample=dataset[500:600]\n",
        "test_correct=correct_tmp[500:600]\n",
        "indices = list(range(len(correct_tmp1)))\n",
        "random.shuffle(indices)\n",
        "split = int(len(indices) * 0.7)\n",
        "training= [training_tmp[i] for i in indices[:split]]\n",
        "correct= [correct_tmp1[i] for i in indices[:split]]\n",
        "training=tf.constant(training)\n",
        "correct=tf.constant(correct)\n",
        "val= [training_tmp[i] for i in indices[split:]]\n",
        "val_cor= [correct_tmp1[i] for i in indices[split:]]\n",
        "val=tf.constant(val)\n",
        "val_cor=tf.constant(val_cor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuwkIHIc4igL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "#load model\n",
        "model=tf.keras.models.load_model(\"predictor6\")\n",
        "\n",
        "#train the model on the data and save it (batch_size and epochs can be played around with to find the ideal numbers)\n",
        "history = model.fit(training, correct, epochs=300, batch_size=32, validation_data=(val,val_cor))\n",
        "model.save(\"predictor6\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvgu3zOQ3Bll"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model=tf.keras.models.load_model(\"predictor6\")\n",
        "\n",
        "test_sample=dataset[500:600]\n",
        "test_correct=correct_tmp[500:600]\n",
        "\n",
        "\n",
        "#if you want to have day by day prediction as oposed to 30 day prediction comment out previous part and uncomment this part\n",
        "dataset_len=100\n",
        "trainining=[]\n",
        "date=[]\n",
        "for i in range(dataset_len):\n",
        "    date.append(i)\n",
        "prediction=model.predict(test_sample)\n",
        "\n",
        "#plot the predicted prices compared to the actual prices\n",
        "plt.figure()\n",
        "plt.plot(date, prediction, label='predictions')\n",
        "plt.plot(date, test_correct, label='actual')\n",
        "plt.title('prediction vs actual')\n",
        "plt.xlabel('date')\n",
        "plt.ylabel('prices')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5POXLze4bxG"
      },
      "outputs": [],
      "source": [
        "#calculate how much money the model makes us on our test sample\n",
        "money=10000\n",
        "for i in range(1,len(prediction)):\n",
        "  #if we predict that the price will go up \"buy\"\n",
        "  estimated_gain=prediction[i][0] - test_correct[i-1]\n",
        "  if estimated_gain>0:\n",
        "    #calclate how much money that day made us\n",
        "    no_share=money/test_correct[i-1]\n",
        "    money=no_share*test_correct[i]\n",
        "\n",
        "#how much money we would have made if the model predicted perfectly\n",
        "money_ideal=10000\n",
        "for i in range(1,len(prediction)):\n",
        "  #if the stock goes up \"buy\"\n",
        "  estimated_gain=test_correct[i]-test_correct[i-1]\n",
        "  if estimated_gain>0:\n",
        "    #calculate how much we make\n",
        "    no_share=money_ideal/test_correct[i-1]\n",
        "    money_ideal=no_share*test_correct[i]\n",
        "\n",
        "print(\"how much we made:\"+money)\n",
        "print(\"max amount we could have made if the model predicted perfectly:\"+money_ideal)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
